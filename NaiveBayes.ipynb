{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8f1b75",
   "metadata": {},
   "source": [
    "# La méthode Naives bayes sur le jeu de de données iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d3e2b",
   "metadata": {},
   "source": [
    "### Résumé\n",
    "La méthode naive bayes est une méthode de classification supervisée qui permet de trouver la classe d'une observation.\n",
    "Pour bien l'aborder, il est important de savoir ce qu'est colonnes ou variables explicatives\n",
    "et la colonne à prdire ou variable expliquer\n",
    "Ici, lorsque nous utilisons le mot classe de la variable dxpliquer, nous ferons réferences aux différentes valeurs de la variables expliquer\n",
    "Les classes d'une variable expliquer sont les différentes valeurs de la variable expliqué.\n",
    "Dans notre contexte, une obseravtion est une tuple de valeur pour les variables explicatives dans un ordre.\n",
    "### Fonctionnement\n",
    "- Avoir un jeu de donnée ( on le chargera souvent avec pd.read_csv)\n",
    "- L'idéale est de répartir ce jeu de données de sorte à avoir un sous ensemble de ce jeu de données comme jeu de donnée d'entrainementn(échantillonnage d'apprentissage) et un autre sous ensemble de ce jeu de données comme echantillonage de test.\n",
    "- Si le jeu de données est très petit, nous pouvons tout le prendre comme jeu de donnée qui va subir d'entrainement (ou d'apprentissage)\n",
    "- Nous ferons souvent la répartition avec sklearn.model_selection import train_test_split\n",
    "\n",
    "- On prend une observation, et on calcule la probabilité pour qu'elle appartienne à chaque élément  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36240c",
   "metadata": {},
   "source": [
    "## Les différents aspects clé de Naive Bayes\n",
    "## Naives bayes avec bernouillies\n",
    "\n",
    "On l'utilise le plus souvent, lorsque les variables explicatives sont binaires c'est à dire 0 ou 1.\n",
    "\n",
    "Naive bayes (X,Y) \n",
    "X ensembles des valeurs explicatives. \n",
    "Les variables explicatives peuvent etre qualitative or quantitative\n",
    "Et Y variables à expliquer. Le Y est une variable qualitative.\n",
    "\n",
    "##  BernoulliNB Naive Bayes. Quand l'utiliser?\n",
    "Lorsque les Xj (les variables explicatives sont des nombres mais binaires (0 ou 1) , c'est à dire quantitatives) alors on utilise Bernoulli de sklearn.naive_bayes. ( adaptés pour la présence ou non d'un parametre/ ou d'une caractéristique) Plus pour les aspects de santés, ou d'étude d'une maladie. Adapté aussi pour du traitement de texte ( détection d'un message spam, ...) \n",
    "\n",
    "##  Gaussian Naive Bayes. Quand l'utiliser?\n",
    "\n",
    "Lorsque les Xj (les variables explicatives sont des nombres, c'est à dire quantitatives) alors on utilise Gaussian de sklearn.naive_bayes\n",
    "\n",
    "\n",
    "\n",
    "##  Multinominale Naive Bayes. Quand l'utiliser?\n",
    "\n",
    "Lorsque les Xj (les variables explicatives sont des nombres mais les valeurs sont des occurences, ou des fréquences. C'est à dire le nombre de fois qu'il apparait,...) alors on utilise Multinominale de sklearn.naive_bayes. Adaptés pour du traitement ou analyse de texte. \n",
    "\n",
    "##  Categorical Naive Bayes. Quand l'utiliser?\n",
    "\n",
    "Meme lorsque les variables explicatives sont des nombres et ne sont pas 0, 1 , Bernoulli Naives bayes a des méthodes pour faire la conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab567d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # pour ignorer les messages d'avertissement\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#permet de calculer les erreurs et l'efficacité du model en comparant les données prédire au données\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split # pour Répartir en base d'apprentissage et de test\n",
    "\n",
    "#Naives bayes\n",
    "from sklearn.naive_bayes import GaussianNB #\n",
    "import pickle # pour la sauvegarde de model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c89258",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde8740",
   "metadata": {},
   "source": [
    "### Importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf3342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal Length  Sepal Width  Petal Length  Petal Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "Le nombre de lignes de data_iris est  150  et le nombre de colonne est :  5\n",
      "Liste des colonnes de data_iris\n",
      "Index(['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width',\n",
      "       'Species'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_iris = pd.read_csv(\"JeuDonneeClass\\iris.csv\")\n",
    "#affichage des 5 premieres lignes\n",
    "print(data_iris.head())\n",
    "#nombre de lignes et de colonnes de data_iris\n",
    "print(\"Le nombre de lignes de data_iris est \",data_iris.shape[0], \" et le nombre de colonne est : \",data_iris.shape[1])\n",
    "#la liste des colonnes de data_iris\n",
    "print('Liste des colonnes de data_iris')\n",
    "print(data_iris.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317bb0c",
   "metadata": {},
   "source": [
    "### Recupération des colonnes explicatives et de la colonnes expliqué\n",
    "Dans data_iris, la derniere colonne est la colonne expliqué (colonne dont on veut prédire des valeurs)\n",
    "Comme c'est la deniere colonne, nous pouvons recupérer toutes les colonnes en faisant du slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0f2c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des cinq premieres lignes de data_explicative\n",
      "   Sepal Length  Sepal Width  Petal Length  Petal Width\n",
      "0           5.1          3.5           1.4          0.2\n",
      "1           4.9          3.0           1.4          0.2\n",
      "2           4.7          3.2           1.3          0.2\n",
      "3           4.6          3.1           1.5          0.2\n",
      "4           5.0          3.6           1.4          0.2\n",
      "Affichons les cinq premieres lignes data_predire\n",
      "0    setosa\n",
      "1    setosa\n",
      "2    setosa\n",
      "3    setosa\n",
      "4    setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "col_explicative = data_iris.columns[:-1] # soit 'Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width',\n",
    "col_A_predire = data_iris.columns[-1] # soit Species\n",
    "#Recupérons les données des colonnes explicatives dans une variable data_explicative\n",
    "data_explicative=data_iris[col_explicative]\n",
    "\n",
    "#Recupérons les données de la colonne expliqué dans une variable data_predire\n",
    "data_predire=data_iris[col_A_predire]\n",
    "\n",
    "# Affichons les 5 premieres lignes de chaque jeu de données \n",
    "print(\"Affichage des cinq premieres lignes de data_explicative\")\n",
    "print(data_explicative.head())\n",
    "print(\"Affichons les cinq premieres lignes data_predire\")\n",
    "print(data_predire.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f8e1e",
   "metadata": {},
   "source": [
    "### Repartissons notre echantillonage en echantillonage de test et d'apprentissage(echantillonge entrainnée)\n",
    "Pour ce fait nous allons utiliser la méthode train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e42fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echantillonage explicative d'apprentissage\n",
      "     Sepal Length  Sepal Width  Petal Length  Petal Width\n",
      "39            5.1          3.4           1.5          0.2\n",
      "36            5.5          3.5           1.3          0.2\n",
      "117           7.7          3.8           6.7          2.2\n",
      "139           6.9          3.1           5.4          2.1\n",
      "107           7.3          2.9           6.3          1.8\n",
      "\n",
      " Echantillonage explicative de test \n",
      "\n",
      "     Sepal Length  Sepal Width  Petal Length  Petal Width\n",
      "14            5.8          4.0           1.2          0.2\n",
      "98            5.1          2.5           3.0          1.1\n",
      "75            6.6          3.0           4.4          1.4\n",
      "16            5.4          3.9           1.3          0.4\n",
      "131           7.9          3.8           6.4          2.0\n",
      "\n",
      " Echantillonage à prédire entrainé \n",
      "\n",
      "39        setosa\n",
      "36        setosa\n",
      "117    virginica\n",
      "139    virginica\n",
      "107    virginica\n",
      "Name: Species, dtype: object\n",
      "\n",
      " Echantillonage à prédire de test \n",
      " \n",
      "14         setosa\n",
      "98     versicolor\n",
      "75     versicolor\n",
      "16         setosa\n",
      "131     virginica\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_explicative_train,data_explicative_test,data_predire_train,data_predire_test=train_test_split(data_explicative, data_predire, test_size=0.33,random_state=1)\n",
    "\n",
    "print(\"Echantillonage explicative d'apprentissage\")\n",
    "print(data_explicative_train.head())\n",
    "print(\"\\n Echantillonage explicative de test \\n\")\n",
    "print(data_explicative_test.head())\n",
    "print(\"\\n Echantillonage à prédire entrainé \\n\")\n",
    "print(data_predire_train.head())\n",
    "print(\"\\n Echantillonage à prédire de test \\n \")\n",
    "print(data_predire_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d48dab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_explicative_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b950f83",
   "metadata": {},
   "source": [
    "### Création de model \n",
    "Ici nous allons entrainer nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a79bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du model en créant un objet de la classe GaussianNB() \n",
    "Naive_Bayes_iris_model= GaussianNB() \n",
    "# entrainement de notre data_explicative_train et data_predire_train avec la méthode fit\n",
    "Naive_Bayes_iris_model.fit(data_explicative_train,data_predire_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca00ed2",
   "metadata": {},
   "source": [
    "### Nous allons tester le model\n",
    "A ce niveau nous donnerons les data_explicative_test au model et nous allons recupérer les prediction dans une variable\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270d56a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes predites pour les exemples de test\n",
      "14         setosa\n",
      "98     versicolor\n",
      "75     versicolor\n",
      "16         setosa\n",
      "131     virginica\n",
      "56     versicolor\n",
      "141     virginica\n",
      "44         setosa\n",
      "29         setosa\n",
      "120     virginica\n",
      "94     versicolor\n",
      "5          setosa\n",
      "102     virginica\n",
      "51     versicolor\n",
      "78     versicolor\n",
      "42         setosa\n",
      "92     versicolor\n",
      "66     versicolor\n",
      "31         setosa\n",
      "35         setosa\n",
      "90     versicolor\n",
      "84     versicolor\n",
      "77     versicolor\n",
      "40         setosa\n",
      "125     virginica\n",
      "99     versicolor\n",
      "33         setosa\n",
      "19         setosa\n",
      "73     versicolor\n",
      "146     virginica\n",
      "91     versicolor\n",
      "135     virginica\n",
      "69     versicolor\n",
      "128     virginica\n",
      "114     virginica\n",
      "48         setosa\n",
      "53     versicolor\n",
      "28         setosa\n",
      "54     versicolor\n",
      "108     virginica\n",
      "112     virginica\n",
      "17         setosa\n",
      "119     virginica\n",
      "103     virginica\n",
      "58     versicolor\n",
      "118     virginica\n",
      "18         setosa\n",
      "4          setosa\n",
      "45         setosa\n",
      "59     versicolor\n",
      "Name: Species, dtype: object\n",
      "classes predites pour les exemples de test\n",
      "['setosa' 'versicolor' 'versicolor' 'setosa' 'virginica' 'virginica'\n",
      " 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor' 'setosa'\n",
      " 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'versicolor'\n",
      " 'setosa' 'setosa' 'versicolor' 'versicolor' 'virginica' 'setosa'\n",
      " 'virginica' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'setosa' 'versicolor' 'virginica' 'virginica' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor' 'virginica' 'setosa' 'setosa'\n",
      " 'setosa' 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "data_predire_du_model=Naive_Bayes_iris_model.predict(data_explicative_test)\n",
    "print(\"classes predites pour les exemples de test\")\n",
    "print(data_predire_test)\n",
    "print(\"classes predites pour les exemples de test\")\n",
    "print(data_predire_du_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737c3ec",
   "metadata": {},
   "source": [
    "### Nous allons maintenant comparer les data_predire\n",
    "\n",
    "### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4d60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efficacite du model pour les exemples de test: 0.94  ,soit :  94.0 %\n",
      "\n",
      "Erreur du model pour les exemples de test:  0.06000000000000005  ,soit :  6.000000000000005 %\n"
     ]
    }
   ],
   "source": [
    "# calculons l'efficacité du model en utilisant la methode accuracy_score de la classe metrics\n",
    "# On doit lui fournir les données_predire_ du test et les données predire du test par le model\n",
    "efficacite =metrics.accuracy_score(data_predire_test,data_predire_du_model)\n",
    "# calculons l'erreur l'erreur est égale à 1 - efficacité\n",
    "erreur=1-efficacite\n",
    "print(\"\\nEfficacite du model pour les exemples de test:\",efficacite,\" ,soit : \",efficacite*100,'%')\n",
    "print(\"\\nErreur du model pour les exemples de test: \",erreur,\" ,soit : \",erreur*100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5fc3fc",
   "metadata": {},
   "source": [
    "### Faisons des prédictions\n",
    "Ici, nous allons fournir à notre model des données explicative, et notre model nous donnera la classe \n",
    "c'est à dire la valeur prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5c701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La classe Species de notre new_data=[[3,5,4,2]] , prédire par notre model est \n",
      " ['versicolor']\n"
     ]
    }
   ],
   "source": [
    "new_data=[[3,5,4,2]] # =3, =5, =4 et =2\n",
    "# nous allons utiliser la méthode predict sur notre model. Et nous allons fournir le new_data en parametre\n",
    "preds=Naive_Bayes_iris_model.predict(new_data)\n",
    "\n",
    "print(\"La classe Species de notre new_data=[[3,5,4,2]] , prédire par notre model est \\n\",preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fda34",
   "metadata": {},
   "source": [
    "### Sauvegarde du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53326ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction du model sauvagardé pour de nouveaux exemples.\n",
      "\n",
      "Les classe de notre new_data=[[3,5,4,2]] , Prédire par notre model est \n",
      " ['versicolor' 'virginica' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(Naive_Bayes_iris_model,open(\"Naive_Bayes_iris_model_obj\",\"wb\"))\n",
    "Naive_Bayes_iris_model_from_pickle=pickle.load(open(\"Naive_Bayes_iris_model_obj\",\"rb\"))\n",
    "print(\"Prediction du model sauvagardé pour de nouveaux exemples.\\n\")\n",
    "new_samples=[[3,5,4,2],[2,3,5,4],[2.5,1.3,3.5,4.0]]\n",
    "preds=Naive_Bayes_iris_model_from_pickle.predict(new_samples)\n",
    "print(\"Les classe de notre new_data=[[3,5,4,2]] , Prédire par notre model est \\n\",preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d897db",
   "metadata": {},
   "source": [
    "### Les matrices de confusions\n",
    "Nous allons utiliser la matrice de confusion pour trouver sur combien d'exemple otre model c'est trompé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb9eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion avec les exemples de test\n",
      "[[17  0  0]\n",
      " [ 0 17  2]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "matrice_confusion = metrics.confusion_matrix(data_predire_test,data_predire_du_model)\n",
    "print('Matrice de confusion avec les exemples de test')\n",
    "print(matrice_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccdb67",
   "metadata": {},
   "source": [
    "### Fin Naives Bayes sur iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a3422",
   "metadata": {},
   "source": [
    "<p style='color:#000'>************************************************* **************************************************** ******************************************************* ***************************************************** ****************************** **************** ************************ **********************************</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e054a",
   "metadata": {},
   "source": [
    "### Début KNN sur iris.csv. Nous allons utiliser les meme echantillonges d'apprentissages et de test utilisé ci dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada2382",
   "metadata": {},
   "source": [
    "### Varions le K pour trouver le K qui donne la meilleure efficacité"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fc0a2a2",
   "metadata": {},
   "source": [
    "accuracy_list=[]\n",
    "#ici, nous allons faire varier le k entre 1 et 30\n",
    "for k in range(1,31):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred= knn.predict(x_test)\n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    accuracy_list.append(acc)\n",
    "\n",
    "k_list=list(range(1,31))\n",
    "print(\"Pour les valeurs de K :\\n\",k_list)\n",
    "print(\"Les valeurs de l'efficacités sont:\")\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e38990",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tracons la courbe K vs Efficacité\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
